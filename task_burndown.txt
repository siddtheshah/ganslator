
Data:
    - Get speech translation data
        > Preferably through fisher spanish-english dataset. But it costs money
        > Columbia might pay for it. Ping the thread on piazza.
        > Alternative is to potentially create your own through anime subs/dubs.
        > That is a heinous amount of work though, and would fill up my hard drive very quickly.

Network:
    - Verify/Inspect wavegan on audio data
        > Need a strong understanding of how wavegan works.
        > Figure out what works and doesn't work on Tensorflow 2.1.0.
        > Will also let me understand how to use audio input.
        > The problems I face is that
    - Write attention mechanism
        > Refer to convolutional attention GAN
    - Write cyclic loss mechanism
        > Refer to cyclegan
    - Rewrite wavegan, verify it can run on sample audio data.
        > Almost certainly necessary.
    - Begin iterating on training data